{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24866f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 csv files, loaded 476 rows, errors: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_all_csvs(directory='.', pattern='*.csv', recursive=False, source_col='source_file'):\n",
    "    p = Path(directory)\n",
    "    files = sorted(p.rglob(pattern) if recursive else p.glob(pattern))\n",
    "    dfs = []\n",
    "    errors = {}\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = pd.read_csv(f, low_memory=False)\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                df = pd.read_csv(f, encoding='latin1', low_memory=False)\n",
    "            except Exception as e:\n",
    "                errors[str(f)] = str(e)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            errors[str(f)] = str(e)\n",
    "            continue\n",
    "        df[source_col] = str(f)  # full path\n",
    "        dfs.append(df)\n",
    "    if not dfs:\n",
    "        combined = pd.DataFrame()\n",
    "    else:\n",
    "        combined = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "    return combined, files, errors\n",
    "\n",
    "combined_df, csv_files, load_errors = load_all_csvs(directory='.', recursive=False)\n",
    "print(f\"Found {len(csv_files)} csv files, loaded {len(combined_df)} rows, errors: {len(load_errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7042f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicate</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Entity Quality</th>\n",
       "      <th>Edge Rank</th>\n",
       "      <th>Score</th>\n",
       "      <th>is_good_predicate</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://schema.org/ratingcount&gt;</td>\n",
       "      <td>0.753135</td>\n",
       "      <td>0.209060</td>\n",
       "      <td>0.860268</td>\n",
       "      <td>0.692534</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>12.588596</td>\n",
       "      <td>True</td>\n",
       "      <td>_http___schema.org_aggregaterating_.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://schema.org/ratingvalue&gt;</td>\n",
       "      <td>0.992617</td>\n",
       "      <td>0.024826</td>\n",
       "      <td>0.422303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>12.497784</td>\n",
       "      <td>True</td>\n",
       "      <td>_http___schema.org_aggregaterating_.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://schema.org/reviewcount&gt;</td>\n",
       "      <td>0.280096</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.526420</td>\n",
       "      <td>0.325808</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>12.487683</td>\n",
       "      <td>True</td>\n",
       "      <td>_http___schema.org_aggregaterating_.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://schema.org/itemreviewed&gt;</td>\n",
       "      <td>0.083455</td>\n",
       "      <td>0.953862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053134</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>12.487263</td>\n",
       "      <td>True</td>\n",
       "      <td>_http___schema.org_aggregaterating_.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://schema.org/bestrating&gt;</td>\n",
       "      <td>0.719100</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.132134</td>\n",
       "      <td>0.593892</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>12.484704</td>\n",
       "      <td>True</td>\n",
       "      <td>_http___schema.org_aggregaterating_.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicate  Frequency  Uniqueness   Entropy  \\\n",
       "0   <http://schema.org/ratingcount>   0.753135    0.209060  0.860268   \n",
       "1   <http://schema.org/ratingvalue>   0.992617    0.024826  0.422303   \n",
       "2   <http://schema.org/reviewcount>   0.280096    0.085644  0.526420   \n",
       "3  <http://schema.org/itemreviewed>   0.083455    0.953862  1.000000   \n",
       "4    <http://schema.org/bestrating>   0.719100    0.000861  0.132134   \n",
       "\n",
       "   Entity Quality  Edge Rank      Score  is_good_predicate  \\\n",
       "0        0.692534   0.006998  12.588596               True   \n",
       "1        1.000000   0.009195  12.497784               True   \n",
       "2        0.325808   0.002848  12.487683               True   \n",
       "3        0.053134   0.001302  12.487263               True   \n",
       "4        0.593892   0.007324  12.484704               True   \n",
       "\n",
       "                               source_file  \n",
       "0  _http___schema.org_aggregaterating_.csv  \n",
       "1  _http___schema.org_aggregaterating_.csv  \n",
       "2  _http___schema.org_aggregaterating_.csv  \n",
       "3  _http___schema.org_aggregaterating_.csv  \n",
       "4  _http___schema.org_aggregaterating_.csv  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29146d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts: neg=390, pos=86 -> class_weights=[0.6102564334869385, 5.534883499145508]\n",
      "Epoch 01 | train_loss: 0.6534 train_acc: 0.5546 | val_loss: 0.6346 val_acc: 0.1807\n",
      "Epoch 02 | train_loss: 0.6322 train_acc: 0.1807 | val_loss: 0.6094 val_acc: 0.1807\n",
      "Epoch 03 | train_loss: 0.6101 train_acc: 0.1807 | val_loss: 0.5898 val_acc: 0.1807\n",
      "Epoch 04 | train_loss: 0.5986 train_acc: 0.1807 | val_loss: 0.5725 val_acc: 0.1807\n",
      "Epoch 05 | train_loss: 0.5767 train_acc: 0.1807 | val_loss: 0.5581 val_acc: 0.1807\n",
      "Epoch 06 | train_loss: 0.5729 train_acc: 0.1807 | val_loss: 0.5457 val_acc: 0.1807\n",
      "Epoch 07 | train_loss: 0.5568 train_acc: 0.1807 | val_loss: 0.5358 val_acc: 0.1807\n",
      "Epoch 08 | train_loss: 0.5530 train_acc: 0.1807 | val_loss: 0.5259 val_acc: 0.1807\n",
      "Epoch 09 | train_loss: 0.5375 train_acc: 0.1807 | val_loss: 0.5166 val_acc: 0.1807\n",
      "Epoch 10 | train_loss: 0.5325 train_acc: 0.1807 | val_loss: 0.5072 val_acc: 0.1807\n",
      "Epoch 11 | train_loss: 0.5370 train_acc: 0.1807 | val_loss: 0.4978 val_acc: 0.1807\n",
      "Epoch 12 | train_loss: 0.5087 train_acc: 0.1807 | val_loss: 0.4892 val_acc: 0.1807\n",
      "Epoch 13 | train_loss: 0.5233 train_acc: 0.2437 | val_loss: 0.4800 val_acc: 0.3319\n",
      "Epoch 14 | train_loss: 0.5083 train_acc: 0.3277 | val_loss: 0.4693 val_acc: 0.4622\n",
      "Epoch 15 | train_loss: 0.4960 train_acc: 0.4118 | val_loss: 0.4585 val_acc: 0.5252\n",
      "Epoch 16 | train_loss: 0.4693 train_acc: 0.5000 | val_loss: 0.4465 val_acc: 0.5504\n",
      "Epoch 17 | train_loss: 0.4624 train_acc: 0.5504 | val_loss: 0.4348 val_acc: 0.5714\n",
      "Epoch 18 | train_loss: 0.4632 train_acc: 0.5672 | val_loss: 0.4231 val_acc: 0.6008\n",
      "Epoch 19 | train_loss: 0.4543 train_acc: 0.6092 | val_loss: 0.4121 val_acc: 0.6639\n",
      "Epoch 20 | train_loss: 0.4304 train_acc: 0.6723 | val_loss: 0.4033 val_acc: 0.7563\n",
      "Epoch 21 | train_loss: 0.4191 train_acc: 0.7521 | val_loss: 0.3937 val_acc: 0.7941\n",
      "Epoch 22 | train_loss: 0.4103 train_acc: 0.7731 | val_loss: 0.3832 val_acc: 0.8193\n",
      "Epoch 23 | train_loss: 0.3917 train_acc: 0.8025 | val_loss: 0.3733 val_acc: 0.8487\n",
      "Epoch 24 | train_loss: 0.3963 train_acc: 0.8151 | val_loss: 0.3630 val_acc: 0.8529\n",
      "Epoch 25 | train_loss: 0.3889 train_acc: 0.8109 | val_loss: 0.3527 val_acc: 0.8487\n",
      "Epoch 26 | train_loss: 0.3778 train_acc: 0.8151 | val_loss: 0.3445 val_acc: 0.8571\n",
      "Epoch 27 | train_loss: 0.3739 train_acc: 0.8151 | val_loss: 0.3378 val_acc: 0.8739\n",
      "Epoch 28 | train_loss: 0.3628 train_acc: 0.8445 | val_loss: 0.3342 val_acc: 0.8866\n",
      "Epoch 29 | train_loss: 0.3581 train_acc: 0.8487 | val_loss: 0.3261 val_acc: 0.8824\n",
      "Epoch 30 | train_loss: 0.3450 train_acc: 0.8445 | val_loss: 0.3192 val_acc: 0.8782\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(5, 16),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.Linear(8, 2),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "features = [\"Frequency\", \"Uniqueness\", \"Entropy\", \"Entity Quality\", \"Edge Rank\"]\n",
    "\n",
    "X = combined_df[features]\n",
    "Y = combined_df[\"is_good_predicate\"]\n",
    "counts = Y.value_counts()\n",
    "pos = int(counts.get(True, 0))\n",
    "neg = int(counts.get(False, 0))\n",
    "\n",
    "if pos == 0:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    # inverse-frequency base weights\n",
    "    total = pos + neg\n",
    "    w0 = total / (2 * neg) if neg > 0 else 1.0\n",
    "    w1 = total / (2 * pos)\n",
    "    recall_bias = 2.0\n",
    "    w1 *= recall_bias\n",
    "    class_weights = torch.tensor([w0, w1], dtype=torch.float32)\n",
    "    print(f\"class counts: neg={neg}, pos={pos} -> class_weights={class_weights.tolist()}\")\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(Y.astype(int).values, dtype=torch.long)\n",
    "\n",
    "# 50/50 split to verify that we do not overfit\n",
    "n_samples = len(X_tensor)\n",
    "perm = torch.randperm(n_samples)\n",
    "split = int(0.5 * n_samples)\n",
    "train_idx, val_idx = perm[:split], perm[split:]\n",
    "\n",
    "train_ds = TensorDataset(X_tensor[train_idx], y_tensor[train_idx])\n",
    "val_ds = TensorDataset(X_tensor[val_idx], y_tensor[val_idx])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "# training loop\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model[:-1](xb) \n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        running_correct += (preds == yb).sum().item()\n",
    "        running_total += xb.size(0)\n",
    "\n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc = running_correct / running_total\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model[:-1](xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            val_correct += (preds == yb).sum().item()\n",
    "            val_total += xb.size(0)\n",
    "\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2aaa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 5)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,                      \n",
    "    dummy_input,                    \n",
    "    \"model.onnx\",               \n",
    "    input_names = ['input'],       \n",
    "    output_names = ['output'],     \n",
    "    opset_version=11             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad1b681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
